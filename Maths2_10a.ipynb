{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\def\\nn{\\nonumber}\n",
    "\\def\\PD#1#2#3{\\dfrac{\\partial^{#1} #2}{\\partial #3^{#1}}}\n",
    "\\def\\eq#1{\\begin{align}#1\\end{align}}\n",
    "\\def\\eqnum#1{\\begin{align}#1\\end{align}}\n",
    "\\def\\dd{\\text{d}}\n",
    "\\def\\DE#1#2#3{\\dfrac{\\dd^{#1} #2}{\\dd #3^{#1}}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple regression analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Outcomes\n",
    "\n",
    "\n",
    "* Introduce the simple linear regression model.\n",
    "* Understanding how to assess the ability of the model to describe variability in datasets.\n",
    "* The application of regression models to engineering problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Simple linear regression is a statistical technique used for establishing a functional link between a *dependent variable* $y$ and an *explanatory variable* (or covariate) $x$, and are among the most frequently used models for statistical analysis of datasets.  They can be used for both (i) assessing the importance (or significance) of an explanatory variable in terms of explaining the observed values of the dependent variable, and (ii) for building functional relationship that can enable prediction of the value of the dependent variable based on a value of the explanatory variable. Only the latter option will be discussed in this note."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As simple linear regression model \n",
    "\n",
    "To introduce the concept of simple linear regression and illustrate how it might be useful in civil engineering, consider the following example based on geotechnical data published by Shirur and Hiremath (2014). As part of a road-building project in the city of Bagalkot (India) it is necessary to undertake a number of saturated California Bearing Ratio (CBR) test to ascertain the mechanical strength of the road substrate.  A problem with this type of CBR test is that each test takes about a week to complete, and as a result only a limited number of tests can realistically be performed along the proposed road-network without causing unacceptable delay and costs.   However, with only a limited number of tests, there is a risk that the underlying variability of CBR values along the road network might not be properly assessed, potentially leading to sub-standard construction.  In an attempt to overcome these problems it was decided to try and develop a simple mathematical relationship that would enable the prediction of CBR values based on the plasticity index (PI) which can be obtained faster, typically 30 minutes for an experienced geotechnical engineer. To establish the link between the two soil properties a total of $n=20$ soil samples were analysed and values of both CBR and PI were obtained for each sample through a series of test in a laboratory.  The results are shown in Table 1. For three of the samples, no values were recorded for the plasticity index, reducing the total sample size from 20 to $n=17$.\n",
    "\n",
    "    \n",
    "| Sample number | PI (%) | CBR (%) |   | Sample number | PI (%) | CBR (%) |\n",
    "|----------------|--------|---------|---|----------------|--------|---------|\n",
    "| 1              | N/A    | 4.84    |   | 11             | 16     | 3.94    |\n",
    "| 2              | 35     | 1.06    |   | 12             | 18.5   | 3.28    |\n",
    "| 3              | 25     | 2.03    |   | 13             | 24     | 2.95    |\n",
    "| 4              | 10     | 4.18    |   | 14             | N/A    | 5.25    |\n",
    "| 5              | 27     | 2.79    |   | 15             | 17.4   | 4.92    |\n",
    "| 6              | 20     | 3.20    |   | 16             | 22.4   | 3.28    |\n",
    "| 7              | 24     | 1.56    |   | 17             | N/A    | 4.92    |\n",
    "| 8              | 28     | 2.54    |   | 18             | 22     | 3.12    |\n",
    "| 9              | 26     | 2.05    |   | 19             | 31     | 1.31    |\n",
    "| 10             | 10.7   | 3.45    |   | 20             | 20     | 1.50    |  \n",
    "***Table 1: Results of lab tests for CBR and PI***\n",
    "\n",
    "\n",
    "As the objective of the data analysis is to predict values of CBR based on values of PI, we therefore define CBR as the dependent variable $Y$ and PI as the explanatory variable $X$.  Plotting the values of CBR against PI for each of the $n=17$ soil samples (see the Figure below) it can be observed that the 17 points appear to to be scattered around a straight line, suggesting that the variation in observed values of CBR can to some extent be explained by the variation in the values of the PI; hence the term explanatory variable. There are several reasons why the points in the Figure below don't lie perfectly on a straight line, including: experimental errors in determining both CBR and PI measurements, and the existence of geotechnical soil properties, other than PI, that determine the CBR values of the soil, but which have not been controlled in this experiment. \n",
    "\n",
    "\n",
    "![](Figures/CBR_PI_plot.png)  \n",
    "***Figure: Values of CBR plotted against corresponding values of PI for n=17 experiments in Table 1***\n",
    "\n",
    "\n",
    "This potential linear relationship can be expressed in the form of a simple linear regression model as\n",
    "\n",
    "$$\\begin{equation}\n",
    "Y=\\underbrace{a_{0}+a_{1}X}_{\\textbf{straight line}}+\\underbrace{\\varepsilon}_{\\textbf{error}}\n",
    "%\\label{eq.reg}\n",
    "\\end{equation}$$\n",
    "\n",
    "where $a_{0}$ and $a_{1}$ are the intercept and slope, respectively, of a straight line, and $\\varepsilon$ is a statistical *error* which is assumed to be a normally distributed random variable with mean zero and variance $\\sigma^{2}$.  The first two terms on the RHS of the above equation defines the, as of yet undefined, best straight line through the data, and the errors represent the vertical distance between the line and each observation.  \n",
    "\n",
    "The following expressions are used for estimating the intercept and the slope of the line:\n",
    "\n",
    "$$\\begin{equation}\n",
    "\\hat{a}_0=\\frac{\\left( \\sum_{i=1}^{n}x_{i}^{2}\\right)\\left( \\sum_{i=1}^{n}y_{i}\\right) -\\left( \\sum_{i=1}^{n}x_{i}\\right)\\left( \\sum_{i=1}^{n}x_{i}y_{i}\\right)}{n\\sum_{i=1}^{n}x_{i}^{2}-\\left( \\sum_{i=1}^{n}x_{i}\\right)^{2}}\n",
    "%\\label{eq.a0}\n",
    "\\end{equation}$$\n",
    "\n",
    "$$\\begin{equation}\n",
    "\\widehat{a}_1=\\frac{n\\left( \\sum_{i=1}^{n}x_{i}y_{i}\\right)-\\left( \\sum_{i=1}^{n}x_{i}\\right)\\left( \\sum_{i=1}^{n}y_{i}\\right)}{n\\sum_{i=1}^{n}x_{i}^{2}-\\left( \\sum_{i=1}^{n}x_{i}\\right)^{2}}\n",
    "%\\label{eq.a1}\n",
    "\\end{equation}$$\n",
    "\n",
    "The $\\widehat{\\phantom{a}}$ notation is used to indicate that the two expressions above are estimators, which can be though of as a rule for calculating an estimate of a given quantity based on observed data.\n",
    "\n",
    "Returning to the example with the $n=17$ soil samples, the line through the points that gives the smallest squared difference between the line and the points can now be calculated using the formulas for $\\hat{a}_0$ and $\\hat{a}_1$.  In the example box below the slope and intercept ($\\hat{a}_{0}$ and $\\hat{a}_{1}$) of the best fit line through the $n=17$ soil observations are derived.\n",
    "\n",
    "If a new value of the explanatory variable $x$ becomes available (e.g. the plasticity index is determined for a new soil sample where CBR has not been measured), then a prediction of the dependent variable $y$ (the required CBR value) can be made as\n",
    "\n",
    "$$\\begin{equation}\n",
    "\\hat{y}=\\hat{a}_{0}+\\hat{a}_1 x\\qquad(8)\n",
    "%\\label{eq.y.predict}\n",
    "\\end{equation}$$\n",
    "\n",
    "where, again, the hat signifies an estimator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Estimating regression model parameters for Indian soils data\n",
    "\n",
    "From the data in Table 1 the following sums are calculated for use in the parameter estimators:     \n",
    "\n",
    "$$\\begin{align}\n",
    "                \\sum_{i=1}^{17}x_{i} &= 381.6\\\\\n",
    "                \\sum_{i=1}^{17}x_{i}^{2} &= 9234.5\\\\\n",
    "                \\sum_{i=1}^{17}y_{i} &= 47.16\\\\\n",
    "                \\sum_{i=1}^{17}y_{i}x_{i} &= 983.24\n",
    "\\end{align}$$\n",
    "\n",
    "which gives the following two regression parameters:\n",
    "\n",
    "$$\\begin{equation*}\n",
    "                \\hat a_{0}=\\frac{9234.5 \\times 47.16 - 381.6 \\times 983.24}{17 \\times 9234.5 - \\left( 381.6\\right) ^{2}} = 5.304\n",
    "\\end{equation*}$$         \n",
    "\n",
    "$$\\begin{equation*}\n",
    "                \\hat a_{1}=\\frac{17\\times 983.24 - 381.6 \\times 47.46}{17 \\times 9234.5 - \\left( 381.6\\right) ^{2}} = -0.113\n",
    "\\end{equation*}$$ \n",
    "                \n",
    "Therefore, the regression line that will enable CBR to predicted from values of PI is given as: $CBR=-0.113\\cdot PI+5.304$ and is shown in the figure below plotted together with the 17 data points.\n",
    "\n",
    "![](Figures/CBR_regression.png)\n",
    "                \n",
    "Notice how the regression line (red) does not give an exact fit to any-one observation, but rather represent the line that result in the lowest values of the summed squared differences between the line and the data points (hence the name of the fitting technique, least squares).            \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigating the fit of a regression model\n",
    "\n",
    "An assessment of the goodness-of-fit of the regression model can be made using both graphical and numerical methods.\n",
    "\n",
    "### Graphical method\n",
    "\n",
    "The residuals $\\varepsilon_{i}$ are defined as the difference between the observed, $y_{i}$, and the fitted, $\\hat{y}_i$ values of the dependent values.  If the residuals are plotted against the exploratory variable $x_{i}$ , then the residuals should ideally show no relation to the $x$ values, and the plot should look like a horizontal blur."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Residual plot for Indian soils data\n",
    "\n",
    "For each of the $n=17$ data points used to derive the regression model relating CBR to PI for the Indian soils data, the corresponding residual $\\varepsilon_{i}$ is calculated as\n",
    "\n",
    "$\\begin{equation}\n",
    "                \\varepsilon_{i}=CBR_{i}-\\left( 0.113\\cdot PI_{i}+5.304\\right) , i=1,\\ldots 17\n",
    "                \\end{equation}$\n",
    "                \n",
    "and plotted against the corresponding values of the plasticity index (PI) as shown in the figure below. \n",
    "\n",
    "![](Figures/CBR_residuals.png)\n",
    "                \n",
    "                \n",
    "The plot shows that the residuals appears to be reasonably randomly scattered around zero with no obvious systematic relationship between the residuals and the values of the plasticity index, which is reassuring.  There is one residual which has a relatively large value.  In such cases it might be useful, if possible, to re-examine the experiment to check if the data can be considered error-free.                \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical assessment\n",
    "\n",
    "A numerical evaluation of how well the regression line fits the observed data can be based on considerations of how much of the total variability in the original data can be explained by the regression model.  \n",
    "\n",
    "The total variation in the data can be explained partly by the sum of the squared residuals.  An often used measure of the quality of the fit of the regression line is the _\"coefficient of determination\"_ $(R^{2})$, defined as the ratio between the variation explained by the regression model and the total variation of the observations, i.e.: \n",
    "\n",
    "$\\begin{equation}\n",
    "R^{2}=\\dfrac{\\sum_{i=1}^{n}\\left(\\hat{y}_{i}- \\bar{y}\\right)^{2}}{\\sum_{i=1}^{n}\\left(y_{i}-\\bar{y} \\right)^2}\n",
    "\\end{equation}$\n",
    "\n",
    "A commonly used variation (based on certain assumptions) is:\n",
    "\n",
    "$\\begin{equation}\n",
    "R^{2}=1- \\dfrac{\\sum_{i=1}^{n}\\left(y_{i}- \\hat{y}\\right)^{2}}{\\sum_{i=1}^{n}\\left(y_{i}-\\bar{y} \\right)^2}\n",
    "\\end{equation}$\n",
    "\n",
    "\n",
    "\n",
    "The better the fit of the regression line is, the smaller the differences between the observations and the line are, i.e., lower values of the sum $\\sum_{i=1}^{n}\\left(y_{i}- \\hat{y}\\right)^{2}$.  If all the observations are located exactly on the line of best fit (i.e. a perfect fit) then that would give $R^{2}=1$ while an increasingly large scatter of the data around the line would result in values of $R^{2}$ less than 1.\n",
    "\n",
    "![](Figures/CBR_regression2.png)  \n",
    "***Figure: Difference between the observation and mean value $(y_{i}-\\bar{y})$ defined as difference between regression line and the mean $(\\hat{y}_{i}-\\bar{y})$ plus the difference between the observation and the regression line $(y_{i}-\\hat{y}_{i})$***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
